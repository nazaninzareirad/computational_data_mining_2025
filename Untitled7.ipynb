{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVN8aVVvA/e+ctUlLKLQY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazaninzareirad/computational_data_mining_2025/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-nWIa6BONatX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615b92cd-e7b7-4917-8a8e-aecb4bbd3fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.12/dist-packages (0.23.4)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo mlxtend"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading and preprocessing the dataset"
      ],
      "metadata": {
        "id": "_AjGFA6Weejj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "# Lloading the dataset\n",
        "online_retail = fetch_ucirepo(id=352)\n",
        "\n",
        "# converting to dataframes\n",
        "X = online_retail.data.features\n",
        "y = online_retail.data.targets\n",
        "\n",
        "# combine into a single DataFrame\n",
        "df = pd.concat([X, y, online_retail.data.ids], axis=1)\n",
        "\n",
        "# convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# remove cancelled transactions\n",
        "df = df[~df['InvoiceNo'].str.startswith('C')]\n",
        "\n",
        "# remove rows with missing CustomerID\n",
        "df = df.dropna(subset=['CustomerID'])\n",
        "\n",
        "# remove quantities that are <= 0\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# remove rows with missing or zero UnitPrice\n",
        "df = df[df['UnitPrice'] > 0]\n"
      ],
      "metadata": {
        "id": "1DksL2mhN-nr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Combine features and targets into a single DataFrame\n",
        "# Include 'InvoiceNo' from online_retail.data.ids\n",
        "df = pd.concat([online_retail.data.features, online_retail.data.targets, online_retail.data.ids], axis=1)\n",
        "\n",
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Filter out cancelled transactions (InvoiceNo starting with 'C')\n",
        "df = df[~df['InvoiceNo'].str.startswith('C')]\n",
        "\n",
        "# Remove rows with missing CustomerID\n",
        "df = df.dropna(subset=['CustomerID'])\n",
        "\n",
        "# Remove negative or zero quantities\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "# Remove rows with missing or zero UnitPrice\n",
        "df = df[df['UnitPrice'] > 0]"
      ],
      "metadata": {
        "id": "dsgz-64eijlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Creating the item-transaction matrix"
      ],
      "metadata": {
        "id": "H-eOuT2juFcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the matrix with pivot_table\n",
        "basket = df.pivot_table(index='InvoiceNo', columns='Description', values='Quantity', aggfunc='sum', fill_value=0)\n",
        "\n",
        "# convert the quantities to binary (1 if purchased, 0 otherwise)\n",
        "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "print(basket.head())"
      ],
      "metadata": {
        "id": "Qm5-YyU4uwJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd32304f-f643-4b3d-fa50-eb1b5839badf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1671543911.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description   4 PURPLE FLOCK DINNER CANDLES   50'S CHRISTMAS GIFT BAG LARGE  \\\n",
            "InvoiceNo                                                                     \n",
            "536365                                    0                               0   \n",
            "536366                                    0                               0   \n",
            "536367                                    0                               0   \n",
            "536368                                    0                               0   \n",
            "536369                                    0                               0   \n",
            "\n",
            "Description   DOLLY GIRL BEAKER   I LOVE LONDON MINI BACKPACK  \\\n",
            "InvoiceNo                                                       \n",
            "536365                        0                             0   \n",
            "536366                        0                             0   \n",
            "536367                        0                             0   \n",
            "536368                        0                             0   \n",
            "536369                        0                             0   \n",
            "\n",
            "Description   I LOVE LONDON MINI RUCKSACK   NINE DRAWER OFFICE TIDY  \\\n",
            "InvoiceNo                                                             \n",
            "536365                                  0                         0   \n",
            "536366                                  0                         0   \n",
            "536367                                  0                         0   \n",
            "536368                                  0                         0   \n",
            "536369                                  0                         0   \n",
            "\n",
            "Description   OVAL WALL MIRROR DIAMANTE    RED SPOT GIFT BAG LARGE  \\\n",
            "InvoiceNo                                                            \n",
            "536365                                 0                         0   \n",
            "536366                                 0                         0   \n",
            "536367                                 0                         0   \n",
            "536368                                 0                         0   \n",
            "536369                                 0                         0   \n",
            "\n",
            "Description   SET 2 TEA TOWELS I LOVE LONDON    SPACEBOY BABY GIFT SET  ...  \\\n",
            "InvoiceNo                                                               ...   \n",
            "536365                                      0                        0  ...   \n",
            "536366                                      0                        0  ...   \n",
            "536367                                      0                        0  ...   \n",
            "536368                                      0                        0  ...   \n",
            "536369                                      0                        0  ...   \n",
            "\n",
            "Description  ZINC STAR T-LIGHT HOLDER   ZINC SWEETHEART SOAP DISH  \\\n",
            "InvoiceNo                                                           \n",
            "536365                               0                          0   \n",
            "536366                               0                          0   \n",
            "536367                               0                          0   \n",
            "536368                               0                          0   \n",
            "536369                               0                          0   \n",
            "\n",
            "Description  ZINC SWEETHEART WIRE LETTER RACK  ZINC T-LIGHT HOLDER STAR LARGE  \\\n",
            "InvoiceNo                                                                       \n",
            "536365                                      0                               0   \n",
            "536366                                      0                               0   \n",
            "536367                                      0                               0   \n",
            "536368                                      0                               0   \n",
            "536369                                      0                               0   \n",
            "\n",
            "Description  ZINC T-LIGHT HOLDER STARS LARGE  ZINC T-LIGHT HOLDER STARS SMALL  \\\n",
            "InvoiceNo                                                                       \n",
            "536365                                     0                                0   \n",
            "536366                                     0                                0   \n",
            "536367                                     0                                0   \n",
            "536368                                     0                                0   \n",
            "536369                                     0                                0   \n",
            "\n",
            "Description  ZINC TOP  2 DOOR WOODEN SHELF   ZINC WILLIE WINKIE  CANDLE STICK  \\\n",
            "InvoiceNo                                                                       \n",
            "536365                                    0                                 0   \n",
            "536366                                    0                                 0   \n",
            "536367                                    0                                 0   \n",
            "536368                                    0                                 0   \n",
            "536369                                    0                                 0   \n",
            "\n",
            "Description  ZINC WIRE KITCHEN ORGANISER  ZINC WIRE SWEETHEART LETTER TRAY  \n",
            "InvoiceNo                                                                   \n",
            "536365                                 0                                 0  \n",
            "536366                                 0                                 0  \n",
            "536367                                 0                                 0  \n",
            "536368                                 0                                 0  \n",
            "536369                                 0                                 0  \n",
            "\n",
            "[5 rows x 3877 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Streaming simulation"
      ],
      "metadata": {
        "id": "jU9BZ7ShY6Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# simulate streaming data by random sampling\n",
        "def stream_data(batch_size=100):\n",
        "    # randomly sample 'batch_size' transactions\n",
        "    indices = np.random.choice(basket.shape[0], batch_size, replace=False)\n",
        "    return basket.iloc[indices]\n",
        "\n",
        "# example of 10 transactions\n",
        "streamed_data = stream_data(10)\n",
        "print(streamed_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faTMaMy4ZKqH",
        "outputId": "304f49aa-9092-408a-d86e-6ddb84f5a1a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description   4 PURPLE FLOCK DINNER CANDLES   50'S CHRISTMAS GIFT BAG LARGE  \\\n",
            "InvoiceNo                                                                     \n",
            "570353                                    0                               0   \n",
            "550513                                    0                               0   \n",
            "542743                                    0                               0   \n",
            "553317                                    0                               0   \n",
            "563036                                    0                               0   \n",
            "\n",
            "Description   DOLLY GIRL BEAKER   I LOVE LONDON MINI BACKPACK  \\\n",
            "InvoiceNo                                                       \n",
            "570353                        0                             0   \n",
            "550513                        0                             0   \n",
            "542743                        0                             0   \n",
            "553317                        0                             0   \n",
            "563036                        0                             0   \n",
            "\n",
            "Description   I LOVE LONDON MINI RUCKSACK   NINE DRAWER OFFICE TIDY  \\\n",
            "InvoiceNo                                                             \n",
            "570353                                  0                         0   \n",
            "550513                                  0                         0   \n",
            "542743                                  0                         0   \n",
            "553317                                  0                         0   \n",
            "563036                                  0                         0   \n",
            "\n",
            "Description   OVAL WALL MIRROR DIAMANTE    RED SPOT GIFT BAG LARGE  \\\n",
            "InvoiceNo                                                            \n",
            "570353                                 0                         0   \n",
            "550513                                 0                         0   \n",
            "542743                                 0                         0   \n",
            "553317                                 0                         0   \n",
            "563036                                 0                         0   \n",
            "\n",
            "Description   SET 2 TEA TOWELS I LOVE LONDON    SPACEBOY BABY GIFT SET  ...  \\\n",
            "InvoiceNo                                                               ...   \n",
            "570353                                      0                        0  ...   \n",
            "550513                                      0                        0  ...   \n",
            "542743                                      0                        0  ...   \n",
            "553317                                      0                        0  ...   \n",
            "563036                                      0                        0  ...   \n",
            "\n",
            "Description  ZINC STAR T-LIGHT HOLDER   ZINC SWEETHEART SOAP DISH  \\\n",
            "InvoiceNo                                                           \n",
            "570353                               0                          0   \n",
            "550513                               0                          0   \n",
            "542743                               0                          0   \n",
            "553317                               0                          0   \n",
            "563036                               0                          0   \n",
            "\n",
            "Description  ZINC SWEETHEART WIRE LETTER RACK  ZINC T-LIGHT HOLDER STAR LARGE  \\\n",
            "InvoiceNo                                                                       \n",
            "570353                                      0                               0   \n",
            "550513                                      0                               0   \n",
            "542743                                      0                               0   \n",
            "553317                                      0                               0   \n",
            "563036                                      0                               0   \n",
            "\n",
            "Description  ZINC T-LIGHT HOLDER STARS LARGE  ZINC T-LIGHT HOLDER STARS SMALL  \\\n",
            "InvoiceNo                                                                       \n",
            "570353                                     0                                0   \n",
            "550513                                     0                                0   \n",
            "542743                                     0                                0   \n",
            "553317                                     0                                0   \n",
            "563036                                     0                                0   \n",
            "\n",
            "Description  ZINC TOP  2 DOOR WOODEN SHELF   ZINC WILLIE WINKIE  CANDLE STICK  \\\n",
            "InvoiceNo                                                                       \n",
            "570353                                    0                                 0   \n",
            "550513                                    0                                 0   \n",
            "542743                                    0                                 0   \n",
            "553317                                    0                                 0   \n",
            "563036                                    0                                 0   \n",
            "\n",
            "Description  ZINC WIRE KITCHEN ORGANISER  ZINC WIRE SWEETHEART LETTER TRAY  \n",
            "InvoiceNo                                                                   \n",
            "570353                                 0                                 0  \n",
            "550513                                 0                                 0  \n",
            "542743                                 0                                 0  \n",
            "553317                                 0                                 0  \n",
            "563036                                 0                                 0  \n",
            "\n",
            "[5 rows x 3877 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Sketching algorithms"
      ],
      "metadata": {
        "id": "VAPlv5L9Zn0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1. Gaussian random projection"
      ],
      "metadata": {
        "id": "Xyl6B7TVaGT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def gaussian_random_projection(X, n_components):\n",
        "    # if the input is a sparse matrix, we extract the shape properly\n",
        "    if isinstance(X, csr_matrix):\n",
        "        n_samples, n_features = X.shape\n",
        "    else:\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "    # when n_components is greater than n_features\n",
        "    if n_components > n_features:\n",
        "        print(f\"Warning: n_components ({n_components}) is greater than \"\n",
        "              f\"n_features ({n_features}). Dimensionality will increase.\")\n",
        "\n",
        "    # 1. generate random projection matrix R with Gaussian entries N(0, 1/sqrt(n_components))\n",
        "    R = np.random.normal(0, 1.0 / np.sqrt(n_components), (n_features, n_components))\n",
        "\n",
        "    # 2. if the input matrix is sparse convert it to dense for multiplication\n",
        "    if isinstance(X, csr_matrix):\n",
        "        X = X.toarray()\n",
        "\n",
        "    # 3. perform the projection: X_new = X @ R\n",
        "    X_new = np.dot(X, R)\n",
        "\n",
        "    return X_new\n",
        "\n",
        "# example\n",
        "if __name__ == \"__main__\":\n",
        "    # 100 transactions (samples) and 50 items (features)\n",
        "    X = np.random.rand(100, 50)\n",
        "\n",
        "    # converting to sparse matrix for efficiency\n",
        "    X_sparse = csr_matrix(X)\n",
        "\n",
        "    # project to 10 dimensions\n",
        "    X_projected = gaussian_random_projection(X_sparse, 10)\n",
        "\n",
        "    print(\"Original shape:\", X.shape)\n",
        "    print(\"Projected shape:\", X_projected.shape)\n",
        "    print(\"Sample of projected data:\\n\", X_projected[:3, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY8SML9naAO8",
        "outputId": "5dbb9de7-e156-4859-fc21-9da5835a9796"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (100, 50)\n",
            "Projected shape: (100, 10)\n",
            "Sample of projected data:\n",
            " [[-1.30317872 -0.67696425  0.21399522 -0.2178603  -0.11859684]\n",
            " [-2.94365669  0.01844226  0.27838148 -1.60349004 -0.61028256]\n",
            " [-3.40023177  0.58844317 -0.06952147 -0.2725474  -1.06387352]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Incremental PCA"
      ],
      "metadata": {
        "id": "dkMeUx0dlpBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Optional, Tuple\n",
        "#converted from the pytorch implementation\n",
        "\n",
        "class IncrementalPCA:\n",
        "\n",
        "    def __init__(self, n_components: Optional[int] = None, batch_size: Optional[int] = None):\n",
        "        self.n_components = n_components\n",
        "        self.batch_size = batch_size\n",
        "        self.n_features_ = None\n",
        "        self.mean_ = None\n",
        "        self.components_ = None\n",
        "        self.singular_values_ = None\n",
        "        self.n_samples_seen_ = 0\n",
        "\n",
        "    def _svd_fn_full(self, X):\n",
        "        # svd computation\n",
        "        return np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "    def _validate_data(self, X) -> np.ndarray:\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = np.array(X, dtype=np.float32)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.n_components is None:\n",
        "            pass\n",
        "        elif self.n_components > n_features:\n",
        "            raise ValueError(\n",
        "                f\"n_components={self.n_components} invalid for n_features={n_features}, \"\n",
        "                \"need more rows than columns for IncrementalPCA processing.\"\n",
        "            )\n",
        "        elif self.n_components > n_samples:\n",
        "            raise ValueError(\n",
        "                f\"n_components={self.n_components} must be less or equal to the batch number of samples {n_samples}\"\n",
        "            )\n",
        "\n",
        "        return X\n",
        "\n",
        "    @staticmethod\n",
        "    def _incremental_mean_and_var(X, last_mean, last_variance, last_sample_count) -> Tuple[np.ndarray, np.ndarray, int]:\n",
        "        if X.shape[0] == 0:\n",
        "            return last_mean, last_variance, last_sample_count\n",
        "\n",
        "        new_sample_count = X.shape[0]\n",
        "        updated_sample_count = last_sample_count + new_sample_count\n",
        "\n",
        "        if last_mean is None:\n",
        "            last_sum = np.zeros(X.shape[1])\n",
        "        else:\n",
        "            last_sum = last_mean * last_sample_count\n",
        "\n",
        "        new_sum = X.sum(axis=0)\n",
        "\n",
        "        updated_mean = (last_sum + new_sum) / updated_sample_count\n",
        "\n",
        "        T = new_sum / new_sample_count\n",
        "        temp = X - T\n",
        "        correction = np.sum(temp, axis=0)**2\n",
        "        temp = temp**2\n",
        "        new_unnormalized_variance = np.sum(temp, axis=0)\n",
        "        new_unnormalized_variance -= correction / new_sample_count\n",
        "        if last_variance is None:\n",
        "            updated_variance = new_unnormalized_variance / updated_sample_count\n",
        "        else:\n",
        "            last_unnormalized_variance = last_variance * last_sample_count\n",
        "            last_over_new_count = last_sample_count / new_sample_count\n",
        "            updated_unnormalized_variance = (\n",
        "                last_unnormalized_variance\n",
        "                + new_unnormalized_variance\n",
        "                + last_over_new_count / updated_sample_count * (last_sum / last_over_new_count - new_sum)**2\n",
        "            )\n",
        "            updated_variance = updated_unnormalized_variance / updated_sample_count\n",
        "\n",
        "        return updated_mean, updated_variance, updated_sample_count\n",
        "    # Fits the model with data X using minibatches of size batch_size.\n",
        "    def fit(self, X: np.ndarray):\n",
        "        X = self._validate_data(X)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.batch_size is None:\n",
        "            self.batch_size = 5 * n_features  # default batch size\n",
        "\n",
        "        # Process data in batches\n",
        "        for batch in range(0, n_samples, self.batch_size):\n",
        "            batch_data = X[batch:batch + self.batch_size]\n",
        "            self.partial_fit(batch_data)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # incrementally fits the model with batch data X\n",
        "    def partial_fit(self, X: np.ndarray):\n",
        "        first_pass = not hasattr(self, \"components_\")\n",
        "\n",
        "        X = self._validate_data(X)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if first_pass:\n",
        "            self.mean_ = None\n",
        "            self.var_ = None\n",
        "            self.n_samples_seen_ = 0\n",
        "            self.n_features_ = n_features\n",
        "            if not self.n_components:\n",
        "                self.n_components = min(n_samples, n_features)\n",
        "\n",
        "        if n_features != self.n_features_:\n",
        "            raise ValueError(\n",
        "                \"number of features of the new batch does not match the number of features of the first batch.\"\n",
        "            )\n",
        "\n",
        "        # calculate incremental mean and variance\n",
        "        col_mean, col_var, n_total_samples = self._incremental_mean_and_var(\n",
        "            X, self.mean_, self.var_, self.n_samples_seen_\n",
        "        )\n",
        "\n",
        "        # center the data by subtracting the column mean\n",
        "        X -= col_mean\n",
        "\n",
        "        # perform SVD on the batch data\n",
        "        U, S, Vt = self._svd_fn_full(X)\n",
        "\n",
        "        # store the top n_components components\n",
        "        self.components_ = Vt[:self.n_components]\n",
        "        self.singular_values_ = S[:self.n_components]\n",
        "        self.mean_ = col_mean\n",
        "        self.var_ = col_var\n",
        "        self.n_samples_seen_ = n_total_samples\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
        "        X = X - self.mean_\n",
        "        return np.dot(X, self.components_.T)\n",
        "\n",
        "    def fit_transform(self, X: np.ndarray) -> np.ndarray:\n",
        "        return self.fit(X).transform(X)\n"
      ],
      "metadata": {
        "id": "VAAQQGhQltBp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Frequent directions"
      ],
      "metadata": {
        "id": "SVDIHm3q332R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#processes data in batches to maintain a sketch matrix B of a fixed size (k, d).\n",
        "#the sketch B is designed such that B^T @ B is a good approximation of A^T @ A, where A is the full data matrix\n",
        "class FrequentDirections:\n",
        "    def __init__(self, n_components: int, n_features: int, batch_size: int = 100):\n",
        "        self.k = n_components\n",
        "        self.n_features = n_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # initialize the sketch matrix B as a (k, d) matrix of zeros\n",
        "        self.sketch = np.zeros((self.k, self.n_features))\n",
        "\n",
        "    def fit(self, A_batch: np.ndarray):\n",
        "        # 1. combine the current sketch B and the new batch A_batch\n",
        "        combined_matrix = np.vstack([self.sketch, A_batch])\n",
        "\n",
        "        # 2. compute the SVD of the combined matrix\n",
        "        try:\n",
        "            U, s, Vt = np.linalg.svd(combined_matrix, full_matrices=False)\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"SVD computation failed. Skipping batch.\")\n",
        "            return\n",
        "\n",
        "        # 3. shrink the sketch\n",
        "        if len(s) <= self.k:\n",
        "            self.sketch = np.zeros((self.k, self.n_features))\n",
        "            reconstructed = s.reshape(-1, 1) * Vt[:len(s), :]\n",
        "            self.sketch[:reconstructed.shape[0], :] = reconstructed\n",
        "        else:\n",
        "            delta = s[self.k - 1]**2\n",
        "\n",
        "            # get the top k squared singular values\n",
        "            s_top_k_squared = s[:self.k]**2\n",
        "\n",
        "            # ensures non-negativity\n",
        "            s_new_squared = np.maximum(0, s_top_k_squared - delta)\n",
        "\n",
        "            s_new = np.sqrt(s_new_squared)\n",
        "\n",
        "            # get the top k right singular vectors (first k rows of Vt)\n",
        "            Vt_top_k = Vt[:self.k, :]\n",
        "\n",
        "            # 4. reconstruct the new sketch B\n",
        "            self.sketch = s_new.reshape(-1, 1) * Vt_top_k\n",
        "\n",
        "    def get_sketch(self):\n",
        "        \"\"\"Returns the current sketch matrix B.\"\"\"\n",
        "        return self.sketch\n",
        "\n",
        "    def get_covariance_approx(self):\n",
        "        \"\"\"Returns the approximation of the covariance matrix (B^T @ B).\"\"\"\n",
        "        return self.sketch.T @ self.sketch\n",
        "\n",
        "\n",
        "# example\n",
        "# 1. define data parameters\n",
        "n_samples = 1000\n",
        "n_features = 50\n",
        "k_components = 20\n",
        "\n",
        "# 2. create sample data (this is where you would use your transaction matrix)\n",
        "X_original = np.random.rand(n_samples, n_features)\n",
        "\n",
        "# 3. Simulate the data stream in batches\n",
        "n_batches = 10\n",
        "batches = np.array_split(X_original, n_batches, axis=0)\n",
        "print(f\"Total data shape: {X_original.shape}\")\n",
        "print(f\"Simulating {n_batches} batches of size {batches[0].shape}\\n\")\n",
        "\n",
        "# 4. initialize the FrequentDirections object\n",
        "fd = FrequentDirections(n_components=k_components, n_features=n_features)\n",
        "\n",
        "# 5. process each batch (as per project Step 4)\n",
        "for i, batch in enumerate(batches):\n",
        "    fd.fit(batch)\n",
        "    print(f\"Processed batch {i+1}/{n_batches}\")\n",
        "\n",
        "# 6. get the final sketch\n",
        "final_sketch = fd.get_sketch()\n",
        "print(f\"\\nFinal sketch shape: {final_sketch.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiBRtC1IryIc",
        "outputId": "36822d54-c839-4acd-e006-215f51f07c29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data shape: (1000, 50)\n",
            "Simulating 10 batches of size (100, 50)\n",
            "\n",
            "Processed batch 1/10\n",
            "Processed batch 2/10\n",
            "Processed batch 3/10\n",
            "Processed batch 4/10\n",
            "Processed batch 5/10\n",
            "Processed batch 6/10\n",
            "Processed batch 7/10\n",
            "Processed batch 8/10\n",
            "Processed batch 9/10\n",
            "Processed batch 10/10\n",
            "\n",
            "Final sketch shape: (20, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. calculating analytic metrics"
      ],
      "metadata": {
        "id": "CX2-z80u-4HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tracemalloc\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from typing import Optional, Tuple\n",
        "import pandas as pd\n",
        "\n",
        "# Gaussian Random Projection (returns projection and R)\n",
        "def gaussian_random_projection(X: np.ndarray, n_components: int, random_state: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Return (X_proj, R) with X_proj = X @ R, R shape = (d, k).\"\"\"\n",
        "    rng = np.random.RandomState(random_state) if random_state is not None else np.random\n",
        "    if isinstance(X, csr_matrix):\n",
        "        X = X.toarray()\n",
        "    n_samples, n_features = X.shape\n",
        "    R = rng.normal(0, 1.0 / np.sqrt(n_components), (n_features, n_components))\n",
        "    X_proj = X @ R\n",
        "    return X_proj, R\n",
        "\n",
        "# IncrementalPCA\n",
        "class IncrementalPCA_custom:\n",
        "    def __init__(self, n_components: Optional[int] = None, batch_size: Optional[int] = None):\n",
        "        self.n_components = n_components\n",
        "        self.batch_size = batch_size\n",
        "        self.n_features_ = None\n",
        "        self.mean_ = None\n",
        "        self.components_ = None\n",
        "        self.singular_values_ = None\n",
        "        self.n_samples_seen_ = 0\n",
        "\n",
        "    def _svd_fn_full(self, X):\n",
        "        return np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "    def _validate_data(self, X):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = np.array(X, dtype=np.float64)\n",
        "        return X\n",
        "\n",
        "    @staticmethod\n",
        "    def _incremental_mean_and_var(X, last_mean, last_variance, last_sample_count):\n",
        "        if X.shape[0] == 0:\n",
        "            return last_mean, last_variance, last_sample_count\n",
        "\n",
        "        new_sample_count = X.shape[0]\n",
        "        updated_sample_count = last_sample_count + new_sample_count\n",
        "\n",
        "        if last_mean is None:\n",
        "            last_sum = np.zeros(X.shape[1])\n",
        "        else:\n",
        "            last_sum = last_mean * last_sample_count\n",
        "\n",
        "        new_sum = X.sum(axis=0)\n",
        "        updated_mean = (last_sum + new_sum) / updated_sample_count\n",
        "\n",
        "        if last_variance is None:\n",
        "            updated_variance = np.var(X, axis=0)\n",
        "        else:\n",
        "            updated_variance = (last_variance * last_sample_count + np.var(X, axis=0) * new_sample_count) / updated_sample_count\n",
        "\n",
        "        return updated_mean, updated_variance, updated_sample_count\n",
        "\n",
        "    def partial_fit(self, X: np.ndarray):\n",
        "        X = self._validate_data(X)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        first_pass = not hasattr(self, \"components_\") or self.components_ is None\n",
        "        if first_pass:\n",
        "            self.mean_ = None\n",
        "            self.var_ = None\n",
        "            self.n_samples_seen_ = 0\n",
        "            self.n_features_ = n_features\n",
        "            if self.n_components is None:\n",
        "                self.n_components = min(n_samples, n_features)\n",
        "\n",
        "        if n_features != self.n_features_:\n",
        "            raise ValueError(\"feature mismatch between batches\")\n",
        "\n",
        "        col_mean, col_var, n_total_samples = self._incremental_mean_and_var(X, self.mean_, self.var_, self.n_samples_seen_)\n",
        "\n",
        "        # we center using the updated mean for this batch (consistent approximation)\n",
        "        X_centered = X - col_mean\n",
        "\n",
        "        # SVD on centered batch\n",
        "        U, S, Vt = self._svd_fn_full(X_centered)\n",
        "\n",
        "        # store top components\n",
        "        self.components_ = Vt[:self.n_components]\n",
        "        self.singular_values_ = S[:self.n_components]\n",
        "        self.mean_ = col_mean\n",
        "        self.var_ = col_var\n",
        "        self.n_samples_seen_ = n_total_samples\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
        "        Xc = X - self.mean_\n",
        "        return np.dot(Xc, self.components_.T)\n",
        "\n",
        "    def inverse_transform(self, X_trans: np.ndarray) -> np.ndarray:\n",
        "        return np.dot(X_trans, self.components_) + self.mean_\n",
        "\n",
        "# FrequentDirections\n",
        "class FrequentDirections_custom:\n",
        "    def __init__(self, n_components: int, n_features: int, batch_size: int = 100):\n",
        "        self.k = n_components\n",
        "        self.n_features = n_features\n",
        "        self.batch_size = batch_size\n",
        "        self.sketch = np.zeros((self.k, self.n_features))\n",
        "\n",
        "    def fit(self, A_batch: np.ndarray):\n",
        "        if A_batch.size == 0:\n",
        "            return\n",
        "        combined_matrix = np.vstack([self.sketch, A_batch])\n",
        "        try:\n",
        "            U, s, Vt = np.linalg.svd(combined_matrix, full_matrices=False)\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"SVD computation failed. Skipping batch.\")\n",
        "            return\n",
        "        if len(s) <= self.k:\n",
        "            self.sketch = np.zeros((self.k, self.n_features))\n",
        "            reconstructed = s.reshape(-1, 1) * Vt[:len(s), :]\n",
        "            self.sketch[:reconstructed.shape[0], :] = reconstructed\n",
        "        else:\n",
        "            delta = s[self.k - 1]**2\n",
        "            s_top_k_squared = s[:self.k]**2\n",
        "            s_new_squared = np.maximum(0, s_top_k_squared - delta)\n",
        "            s_new = np.sqrt(s_new_squared)\n",
        "            Vt_top_k = Vt[:self.k, :]\n",
        "            self.sketch = s_new.reshape(-1, 1) * Vt_top_k\n",
        "\n",
        "    def get_sketch(self):\n",
        "        return self.sketch\n",
        "\n",
        "    def get_covariance_approx(self):\n",
        "        return self.sketch.T @ self.sketch\n",
        "\n",
        "    def get_representation_and_projection(self):\n",
        "        \"\"\"Return V (d x k) and projection P = V @ V.T (d x d).\"\"\"\n",
        "        B = self.sketch\n",
        "        U, s, Vt = np.linalg.svd(B, full_matrices=False)\n",
        "        Vt_top = Vt[:self.k, :]\n",
        "        V = Vt_top.T  # (d, k)\n",
        "        P = V @ V.T\n",
        "        return V, P\n",
        "\n",
        "    def reconstruct_projection(self, A: np.ndarray):\n",
        "        \"\"\"Return A @ P as the reconstruction in original space.\"\"\"\n",
        "        _, P = self.get_representation_and_projection()\n",
        "        return A @ P\n",
        "\n",
        "\n",
        "# Metrics (relative)\n",
        "def relative_frobenius_cov_error(A: np.ndarray, A_approx: np.ndarray) -> float:\n",
        "    cov_A = A.T @ A\n",
        "    cov_A_approx = A_approx.T @ A_approx\n",
        "    num = np.linalg.norm(cov_A - cov_A_approx, ord='fro')\n",
        "    den = np.linalg.norm(cov_A, ord='fro')\n",
        "    return float(num / max(den, 1e-12))\n",
        "\n",
        "def relative_reconstruction_error(A: np.ndarray, A_recon: np.ndarray) -> float:\n",
        "    num = np.linalg.norm(A - A_recon, ord='fro')\n",
        "    den = np.linalg.norm(A, ord='fro')\n",
        "    return float(num / max(den, 1e-12))\n",
        "\n",
        "def explained_variance_ratio(A: np.ndarray, representation: np.ndarray) -> float:\n",
        "    total_var = float(np.sum(np.var(A, axis=0)))\n",
        "    rep_var = float(np.sum(np.var(representation, axis=0)))\n",
        "    return float(rep_var / max(total_var, 1e-12))\n",
        "\n",
        "\n",
        "# Streaming evaluation harness\n",
        "def evaluate_streaming_custom(\n",
        "    X: np.ndarray,\n",
        "    n_batches: int = 10,\n",
        "    fd_k: int = 20,\n",
        "    rp_k: int = 20,\n",
        "    ipca_k: Optional[int] = None,\n",
        "    random_state: Optional[int] = 0\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Processes X as a stream in n_batches and computes metrics for your custom algorithms.\n",
        "    \"\"\"\n",
        "    if isinstance(X, csr_matrix):\n",
        "        X = X.toarray()\n",
        "    n_samples, n_features = X.shape\n",
        "    if ipca_k is None:\n",
        "        ipca_k = min(fd_k, n_features)\n",
        "\n",
        "    batches = np.array_split(X, n_batches, axis=0)\n",
        "    ipca = IncrementalPCA_custom(n_components=ipca_k)\n",
        "    fd = FrequentDirections_custom(n_components=fd_k, n_features=n_features)\n",
        "\n",
        "    results = []\n",
        "    cumulative = None\n",
        "\n",
        "    for i, batch in enumerate(batches, start=1):\n",
        "        if batch.size == 0:\n",
        "            continue\n",
        "        cumulative = batch.copy() if cumulative is None else np.vstack([cumulative, batch])\n",
        "\n",
        "        fd.fit(batch)\n",
        "        B = fd.get_sketch()\n",
        "        A_fd_recon = fd.reconstruct_projection(cumulative)\n",
        "        V_fd, _ = fd.get_representation_and_projection()\n",
        "        rep_fd = cumulative @ V_fd\n",
        "\n",
        "        # Gaussian Random Projection: project and back-project with pinv\n",
        "        X_rp, R = gaussian_random_projection(cumulative, rp_k, random_state=(random_state or 0) + i)\n",
        "        R_pinv = np.linalg.pinv(R)\n",
        "        X_rp_recon = X_rp @ R_pinv\n",
        "        # representation for RP is X_rp (n_cum, k)\n",
        "\n",
        "        # Incremental PCA\n",
        "        ipca.partial_fit(batch)\n",
        "        X_ipca_trans = ipca.transform(cumulative)\n",
        "        X_ipca_recon = ipca.inverse_transform(X_ipca_trans)\n",
        "\n",
        "        # metrics\n",
        "        cov_fd = relative_frobenius_cov_error(cumulative, A_fd_recon)\n",
        "        cov_rp = relative_frobenius_cov_error(cumulative, X_rp_recon)\n",
        "        cov_ipca = relative_frobenius_cov_error(cumulative, X_ipca_recon)\n",
        "\n",
        "        recon_fd = relative_reconstruction_error(cumulative, A_fd_recon)\n",
        "        recon_rp = relative_reconstruction_error(cumulative, X_rp_recon)\n",
        "        recon_ipca = relative_reconstruction_error(cumulative, X_ipca_recon)\n",
        "\n",
        "        evr_fd = explained_variance_ratio(cumulative, rep_fd)\n",
        "        evr_rp = explained_variance_ratio(cumulative, X_rp)\n",
        "        evr_ipca = explained_variance_ratio(cumulative, X_ipca_trans)\n",
        "\n",
        "        results.append({\n",
        "            \"batch\": i,\n",
        "            \"seen_samples\": cumulative.shape[0],\n",
        "\n",
        "            \"FD_cov_frob_rel\": cov_fd,\n",
        "            \"RP_cov_frob_rel\": cov_rp,\n",
        "            \"IPCA_cov_frob_rel\": cov_ipca,\n",
        "\n",
        "            \"FD_recon_rel\": recon_fd,\n",
        "            \"RP_recon_rel\": recon_rp,\n",
        "            \"IPCA_recon_rel\": recon_ipca,\n",
        "\n",
        "            \"FD_explained_var_ratio\": evr_fd,\n",
        "            \"RP_explained_var_ratio\": evr_rp,\n",
        "            \"IPCA_explained_var_ratio\": evr_ipca,\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# example\n",
        "if __name__ == \"__main__\":\n",
        "    rng = np.random.default_rng(42)\n",
        "    X_example = rng.random((1000, 50))\n",
        "\n",
        "    df_metrics = evaluate_streaming_custom(\n",
        "        X_example,\n",
        "        n_batches=10,\n",
        "        fd_k=20,\n",
        "        rp_k=20,\n",
        "        ipca_k=20,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(df_metrics)\n",
        "    df_metrics.to_csv(\"/content/section5_metrics_custom_impls.csv\", index=False)\n",
        "    print(\"Saved CSV: /content/section5_metrics_custom_impls.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vowCi1iW-_mS",
        "outputId": "1a8a53de-1ac5-4d00-b829-df2929f975e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   batch  seen_samples  FD_cov_frob_rel  RP_cov_frob_rel  IPCA_cov_frob_rel  \\\n",
            "0      1           100         0.022856         0.932227           0.020988   \n",
            "1      2           200         0.027745         0.955224           0.032225   \n",
            "2      3           300         0.030167         0.862451           0.034078   \n",
            "3      4           400         0.030999         0.956259           0.033979   \n",
            "4      5           500         0.032104         0.965405           0.034649   \n",
            "5      6           600         0.032610         0.898163           0.034868   \n",
            "6      7           700         0.033235         0.909572           0.035565   \n",
            "7      8           800         0.033626         0.891303           0.035512   \n",
            "8      9           900         0.033742         0.967269           0.035226   \n",
            "9     10          1000         0.033978         0.909710           0.035319   \n",
            "\n",
            "   FD_recon_rel  RP_recon_rel  IPCA_recon_rel  FD_explained_var_ratio  \\\n",
            "0      0.286462      0.794222        0.275271                0.673096   \n",
            "1      0.324905      0.826678        0.338699                0.578788   \n",
            "2      0.342805      0.723571        0.357172                0.527757   \n",
            "3      0.349386      0.827133        0.361053                0.510155   \n",
            "4      0.356545      0.842709        0.366756                0.490645   \n",
            "5      0.360703      0.757138        0.370178                0.477095   \n",
            "6      0.365089      0.769390        0.375253                0.465353   \n",
            "7      0.367798      0.749610        0.376060                0.456938   \n",
            "8      0.368971      0.845413        0.375315                0.454036   \n",
            "9      0.370509      0.769951        0.376241                0.448737   \n",
            "\n",
            "   RP_explained_var_ratio  IPCA_explained_var_ratio  \n",
            "0                1.033005                  0.698112  \n",
            "1                0.988396                  0.542249  \n",
            "2                0.983114                  0.487331  \n",
            "3                1.032016                  0.476886  \n",
            "4                0.979379                  0.461047  \n",
            "5                1.085789                  0.449259  \n",
            "6                0.999604                  0.435166  \n",
            "7                1.018796                  0.432261  \n",
            "8                0.991571                  0.435094  \n",
            "9                0.966749                  0.431544  \n",
            "Saved CSV: /content/section5_metrics_custom_impls.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. graphs"
      ],
      "metadata": {
        "id": "MxR_66gVAuDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzywP5DQBipq",
        "outputId": "36b5d34c-c05f-4dff-80da-1e286a9fb5ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "MARKERS = {'FD': 'o', 'RP': 's', 'IPCA': 'D'}\n",
        "COLORS = {'FD': '#1f77b4', 'RP': '#ff7f0e', 'IPCA': '#2ca02c'}\n",
        "\n",
        "def load_metrics(csv_path: str = \"/content/section5_metrics_custom_impls.csv\"):\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Loaded metrics from {csv_path}\")\n",
        "        return df\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Metrics CSV not found at: {csv_path}. Create it with evaluate_streaming_custom().\")\n",
        "\n",
        "def plot_metric_over_batches(df: pd.DataFrame, metric_keys: dict, title: str, ylabel: str, outpath: str = None):\n",
        "    plt.figure(figsize=(9,5))\n",
        "    batches = df['batch'].values\n",
        "    for alg, col in metric_keys.items():\n",
        "        if col not in df.columns:\n",
        "            print(f\"Warning: column '{col}' not found in DataFrame. Skipping {alg}.\")\n",
        "            continue\n",
        "        y = df[col].values\n",
        "        plt.plot(batches, y, marker=MARKERS.get(alg, 'o'), label=alg, color=COLORS.get(alg))\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    if outpath:\n",
        "        plt.savefig(outpath, dpi=200)\n",
        "        print(f\"Saved: {outpath}\")\n",
        "    plt.show()\n",
        "\n",
        "def summarize_and_compare(df: pd.DataFrame):\n",
        "    algs = ['FD', 'RP', 'IPCA']\n",
        "    metrics = {\n",
        "        'cov_frob': ('{}_cov_frob_rel', 'Relative Frobenius (cov)'),\n",
        "        'recon': ('{}_recon_rel', 'Relative reconstruction error'),\n",
        "        'evr': ('{}_explained_var_ratio', 'Explained variance ratio'),\n",
        "    }\n",
        "    rows = []\n",
        "    for alg in algs:\n",
        "        row = {'alg': alg}\n",
        "        for mkey, (fmt, label) in metrics.items():\n",
        "            col = fmt.format(alg)\n",
        "            if col not in df.columns:\n",
        "                row[f'{mkey}_mean'] = np.nan\n",
        "                row[f'{mkey}_std'] = np.nan\n",
        "                row[f'{mkey}_final'] = np.nan\n",
        "            else:\n",
        "                vals = df[col].values\n",
        "                row[f'{mkey}_mean'] = float(np.nanmean(vals))\n",
        "                row[f'{mkey}_std'] = float(np.nanstd(vals))\n",
        "                row[f'{mkey}_final'] = float(vals[-1])\n",
        "        time_col = f\"{alg}_time\"\n",
        "        if time_col in df.columns:\n",
        "            row['time_mean_s'] = float(np.nanmean(df[time_col].values))\n",
        "            row['time_std_s'] = float(np.nanstd(df[time_col].values))\n",
        "        else:\n",
        "            row['time_mean_s'] = np.nan\n",
        "            row['time_std_s'] = np.nan\n",
        "        rows.append(row)\n",
        "    summary = pd.DataFrame(rows).set_index('alg')\n",
        "    analysis_lines = []"
      ],
      "metadata": {
        "id": "fjNoJG5YAxZW"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}